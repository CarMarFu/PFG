{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOMiiQrj1FpZFo+otxFNql4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Se va a seguir el tutorial encontrado en [https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker/python](https://ai.google.dev/edge/mediapipe/solutions/vision/hand_landmarker/python)"],"metadata":{"id":"8LZdwBSN97t_"}},{"cell_type":"markdown","source":["Instalamos la librería necesaria"],"metadata":{"id":"24ZnCS_48_GV"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xntnd2RD8OQF","executionInfo":{"status":"ok","timestamp":1741273789903,"user_tz":-60,"elapsed":6245,"user":{"displayName":"Carlos Martínez De La Fuente","userId":"07400293183790881695"}},"outputId":"fdf37561-5e58-426d-850c-cb6ea1393c99"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n","Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.1.0)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n","Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.4.33)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n","Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.4)\n","Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n","Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.6)\n","Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n","Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n","Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n","Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.13.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.56.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.4)\n"]}],"source":["!python -m pip install mediapipe\n","!pip install opencv-python"]},{"cell_type":"markdown","source":["Importamos librerías y modelo de reconocimiento de mano"],"metadata":{"id":"wq8McoDb9LW6"}},{"cell_type":"code","source":["import mediapipe as mp\n","from mediapipe.tasks import python\n","from mediapipe.tasks.python import vision\n","import pandas as pd\n","\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","model_path = '/content/drive/MyDrive/PFG/Hand Recording Demo/hand_landmarker.task'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nIEewG4V9M8K","executionInfo":{"status":"ok","timestamp":1741275783635,"user_tz":-60,"elapsed":1094,"user":{"displayName":"Carlos Martínez De La Fuente","userId":"07400293183790881695"}},"outputId":"b89b5bd8-9813-4ce9-a7a4-bc462eb1264c"},"execution_count":30,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","source":["BaseOptions = mp.tasks.BaseOptions\n","HandLandmarker = mp.tasks.vision.HandLandmarker\n","HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n","VisionRunningMode = mp.tasks.vision.RunningMode\n","\n","# Create a hand landmarker instance with the video mode:\n","options = HandLandmarkerOptions(\n","    base_options=BaseOptions(model_asset_path=model_path),\n","    running_mode=VisionRunningMode.VIDEO)\n","with HandLandmarker.create_from_options(options) as landmarker:\n","    # El landmarker está inicializado. Aquí puedes procesar las imágenes.\n","    # Por ejemplo, para procesar una imagen:\n","    # image = cv2.imread('your_image.jpg')  # Cargar imagen (asegúrate de usar OpenCV u otra biblioteca para cargar imágenes)\n","    # results = landmarker.detect(image)\n","    # ... (Aquí iría el procesamiento adicional)\n","    pass"],"metadata":{"id":"skPha3gq-NyF","executionInfo":{"status":"ok","timestamp":1741275784535,"user_tz":-60,"elapsed":6,"user":{"displayName":"Carlos Martínez De La Fuente","userId":"07400293183790881695"}}},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":["Procesar el vídeo"],"metadata":{"id":"zpvUOpJCA065"}},{"cell_type":"code","source":["import cv2\n","from google.colab.patches import cv2_imshow\n","\n","# Inicializar MediaPipe Hands\n","mp_hands = mp.solutions.hands\n","mp_drawing = mp.solutions.drawing_utils\n","\n","# Cargar el video\n","video_path = '/content/drive/MyDrive/PFG/Hand Recording Demo/hand_rec_demo_video.mp4'\n","cap = cv2.VideoCapture(video_path)\n","\n","# Lista para almacenar las coordenadas\n","data = []\n","\n","# Obtener propiedades del video original\n","fps = int(cap.get(cv2.CAP_PROP_FPS))\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","# Definir el codec y crear un VideoWriter para guardar el video procesado\n","output_path = \"/content/drive/MyDrive/PFG/Hand Recording Demo/video_procesado_demo.mp4\"\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Codec para MP4\n","out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n","\n","# Configurar MediaPipe Hands\n","with mp_hands.Hands(static_image_mode=False, max_num_hands=1, min_detection_confidence=0.5) as hands:\n","    frame_id = 0  # Contador de frames\n","\n","    while cap.isOpened():\n","        ret, frame = cap.read()\n","        if not ret:\n","            break\n","\n","        frame_id += 1  # Aumentar contador de frames\n","        print(f\"Procesando frame {frame_id}\")\n","\n","        # Convertir BGR a RGB para MediaPipe\n","        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","\n","        # Procesar el frame con MediaPipe Hands\n","        results = hands.process(frame_rgb)\n","\n","        # Extraer coordenadas si se detectan manos\n","        if results.multi_hand_landmarks:\n","            for hand_idx, hand_landmarks in enumerate(results.multi_hand_landmarks):\n","                for i, landmark in enumerate(hand_landmarks.landmark):\n","                    data.append({\n","                        \"frame\": frame_id,\n","                        \"hand_id\": hand_idx,\n","                        \"landmark_id\": i,\n","                        \"x\": landmark.x,\n","                        \"y\": landmark.y,\n","                        \"z\": landmark.z\n","                    })\n","\n","        # Dibujar landmarks si se detectan manos\n","        if results.multi_hand_landmarks:\n","            for hand_landmarks in results.multi_hand_landmarks:\n","                mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n","\n","        # Guardar el frame en el nuevo video\n","        out.write(frame)\n","\n","# Liberar recursos\n","cap.release()\n","out.release()\n","\n","# Guardar en CSV las coordenadas\n","df = pd.DataFrame(data)\n","csv_path = \"/content/drive/MyDrive/PFG/Hand Recording Demo/landmarks_demo.csv\"\n","df.to_csv(csv_path, index=False)\n","\n","print(f\"Datos guardados en: {csv_path}\")\n","\n","print(f\"Video procesado guardado en: {output_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":818},"id":"K4805xRuCZp5","outputId":"1855850e-072d-48fc-bab1-5475a3df3db5","executionInfo":{"status":"error","timestamp":1741275980213,"user_tz":-60,"elapsed":2436,"user":{"displayName":"Carlos Martínez De La Fuente","userId":"07400293183790881695"}}},"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["Procesando frame 1\n","Procesando frame 2\n","Procesando frame 3\n","Procesando frame 4\n","Procesando frame 5\n","Procesando frame 6\n","Procesando frame 7\n","Procesando frame 8\n","Procesando frame 9\n","Procesando frame 10\n","Procesando frame 11\n","Procesando frame 12\n","Procesando frame 13\n","Procesando frame 14\n","Procesando frame 15\n","Procesando frame 16\n","Procesando frame 17\n","Procesando frame 18\n","Procesando frame 19\n","Procesando frame 20\n","Procesando frame 21\n","Procesando frame 22\n","Procesando frame 23\n","Procesando frame 24\n","Procesando frame 25\n","Procesando frame 26\n","Procesando frame 27\n","Procesando frame 28\n","Procesando frame 29\n","Procesando frame 30\n","Procesando frame 31\n","Procesando frame 32\n","Procesando frame 33\n","Procesando frame 34\n","Procesando frame 35\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-35-e56c5939417a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;31m# Guardar el frame en el nuevo video\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;31m# Liberar recursos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}